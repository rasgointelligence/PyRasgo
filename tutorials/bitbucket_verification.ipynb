{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook will help you register any Rasgo datasets checked into your Version Control system as 'verified' if they exist in the main branch of your repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Rasgo datasets and create YAML file representations for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pyrasgo\n",
    "import requests\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyrasgo connection\n",
    "api_key = \"...\"\n",
    "rasgo = pyrasgo.connect(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd into your git dir \n",
    "%cd path/to/your/git/dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all Rasgo Datasets\n",
    "# alternatvely, just get a list of resource keys you want to set the \"git_sync\" status to False (i.e. Datasets awaiting approval in a PR)\n",
    "datasets = rasgo.get.datasets(published_only=True, include_community=False)\n",
    "\n",
    "# Rasgo dataset repo directory name\n",
    "    # At the root of your directory, you should have a subdirectory that contains the YAML representations for your Rasgo \n",
    "    # dataset.\n",
    "rasgo_ds_dir_name = \"rasgo\"\n",
    "\n",
    "# generate and write out yaml file representation for each dataset\n",
    "for ds in datasets:\n",
    "    ds.generate_yaml(file_path=f\"{rasgo_ds_dir_name}/{ds.resource_key}.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commit Rasgo YAML dataset representation to your repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you should:\n",
    "1. Create a branch for your new dataset representations\n",
    "2. Open a PR from your new branch to the repository's main branch\n",
    "3. \\[OPTIONAL\\] Update your PR-ed datasets to show that they are currently waiting to be approved by setting the `git_sync` attribute to `False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Step 3:\n",
    "# Update dataset attributes so users know these datasets are in a PR and are currently waiting on review\n",
    "for ds in datasets:\n",
    "    rasgo.update.dataset(dataset=ds, attributes={'git_sync':'False'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. When PR-ed datasets have been reviewed and accepted, merge the PR to master/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Scan repository's main branch for datasets and set the `git_sync` attribute for each dataset found\n",
    "\n",
    "Update Dataset attributes to show that changes have been accepted and approved for consumption by users by setting `git_sync` to `True`. Any dataset on the main/master branch is assumed to be valid and available for consumption.\n",
    "\n",
    "This can be done either using the Bitbucket API or using standard git user access. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Git CLI Method\n",
    "Use git commands to get dataset files\n",
    "\n",
    "For getting your local env (or a jupyter env) set up with shh/https git creds, check [the bitbucket docs](https://support.atlassian.com/bitbucket-cloud/docs/set-up-an-ssh-key/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ~/path/to/your/git/dir\n",
    "# Check out the main/master branch and make sure it's up to date\n",
    "!git checkout master \n",
    "!git pull\n",
    "\n",
    "import os \n",
    "# file names should be resource keys\n",
    "resource_keys = [x.replace('.yaml', '') for x in  os.listdir(rasgo_ds_dir_name) if '.yaml' in x]\n",
    "\n",
    "# If found, set dataset attribute for each\n",
    "for ds_rk in resource_keys:\n",
    "    ds = rasgo.get.dataset(resource_key=ds_rk)\n",
    "    rasgo.update.dataset(dataset=ds, attributes={\"git_sync\": \"True\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitbucket API Method\n",
    "If you have to use the Bitbucket API, get a list of datasets to update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instructions on how to get API token\n",
    "\n",
    "# Set up OAuth consumer in the bitbucket workspace [here](https://support.atlassian.com/bitbucket-cloud/docs/use-oauth-on-bitbucket-cloud/)\n",
    "\n",
    "oauth_key = \"YOUR OAUTH KEY\"\n",
    "oauth_secret = \"YOUR OAUTH SECRET\"\n",
    "\n",
    "# Get authorization token form OAuth\n",
    "# Bitbucket auth token access\n",
    "data = {\"grant_type\": \"client_credentials\"}\n",
    "token_request = requests.post(\"https://bitbucket.org/site/oauth2/access_token\", data=data, auth=(oauth_key, oauth_secret))\n",
    "api_token = token_request.json().get(\"access_token\")\n",
    "\n",
    "token: str = (\n",
    "    f\"Bearer {api_token}\"\n",
    ")\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": token\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_version = \"2.0\"\n",
    "\n",
    "# For bitbucket cloud, use this server URL\n",
    "bitbucket_cloud_api_host = f\"https://api.bitbucket.org/{api_version}\"\n",
    "\n",
    "# Enter your repo's workspace name here. This needs to be the same workspace in which you set up the OAuth consumer in the cell above\n",
    "bitbucket_workspace_name = \"...\"\n",
    "\n",
    "# Enter your repo's slug here - if you don't know it, you can find it on your repository's page\n",
    "bitbucket_repo_slug = \"...\"\n",
    "\n",
    "# Choose the branch from which you'd like to get YAML files to set verification - the default assumption here is \"main\"\n",
    "bitbucket_main_branch_name = \"main\"\n",
    "\n",
    "get_url = f\"{bitbucket_cloud_api_host}/repositories/{bitbucket_workspace_name}/{bitbucket_repo_slug}/src/{bitbucket_main_branch_name}/{rasgo_ds_dir_name}/\"\n",
    "resource_keys = []\n",
    "while True:\n",
    "    page = requests.get(get_url, headers=headers)\n",
    "\n",
    "    if page.status_code != 200:\n",
    "        raise ValueError(\"Issue retrieving data from biqtbucket API\")\n",
    "\n",
    "    results = page.json()[\"values\"]\n",
    "    # file names should be resource keys\n",
    "    resource_keys.extend([p[\"path\"].replace(\".yaml\", \"\") for p in results if p[\"path\"].endswith(\".yaml\")])\n",
    "    \n",
    "    # this page wasn't empty, let's get the next page\n",
    "    if results and (next_page_url := results.get(\"next\")):\n",
    "        get_url = next_page_url\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "# If found, set dataset attribute for each\n",
    "for ds_rk in resource_keys:\n",
    "    ds = rasgo.get.dataset(resource_key=ds_rk)\n",
    "    rasgo.update.dataset(dataset=ds, attributes={\"git_sync\": \"True\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
